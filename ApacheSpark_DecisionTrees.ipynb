{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark-Mllib: Decision trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees (DTs) and their ensembles are popular methods for the machine learning task of a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n",
    "\n",
    "\n",
    "Some advantages of decision trees are:\n",
    "<li>Simple to understand and to interpret. Trees can be visualised.</li>\n",
    "<li>Requires little data and feature preparation. </li>\n",
    "<li>Able to handle both numerical and categorical data. </li>\n",
    "<li>Able to handle multi-output problems.</li>\n",
    "<li>Possible to validate a model using statistical tests. </li>\n",
    "<li>Performs well even if its assumptions are somewhat violated by the true model from which the data were generated.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Decision Trees: Algorithmic Background </h2>\n",
    "<p>\n",
    "<img src=\"https://databricks.com/wp-content/uploads/2014/09/decision-tree-example.png\" alt=\"Mountain View\" style=\"width:304px;height:228px;\">\n",
    "\n",
    "\n",
    "<p>\n",
    "A model is learned from a training dataset by building a tree top-down. The if-else statements, also known as splitting criteria, are chosen to maximize a notion of information gain â€” it reduces the variability of the labels in the underlying (two) child nodes compared the parent node. The learned decision tree model can later be used to predict the labels for new instances.\n",
    "\n",
    "These models are interpretable, and they often work well in practice. Trees may also be combined to build even more powerful models, using ensemble tree algorithms. Ensembles of trees such as random forests and boosted trees are often top performers in industry for both classification and regression tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data and creating the RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Initializing Spark</h2>\n",
    "<p>The first thing a Spark program must do is to create a SparkContext object, which tells Spark how to access a cluster.\n",
    "To create a SparkContext you first need to build a SparkConf object that contains information about your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkConf, SparkContext,SQLContext\n",
    "sc = SparkContext(\"local\",\"App:DecisionTrees\")\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training Dataset </h3>\n",
    "<p> Get the training data from web. You have data in the Data/KDD folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size is 4898431\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "#f = urllib.urlretrieve (\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data.gz\", \"Data/kddcup.data.gz\")\n",
    "data_file = \"Data/KDD/kddcup.data.gz\"\n",
    "raw_data = sc.textFile(data_file)\n",
    "print \"Train data size is {}\".format(raw_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Testing Dataset </h3>\n",
    "<p> Get the testing data from web. You have data in the Data/KDD folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data size is 311029\n"
     ]
    }
   ],
   "source": [
    "#ft = urllib.urlretrieve(\"http://kdd.ics.uci.edu/databases/kddcup99/corrected.gz\", \"Data/KDD/corrected.gz\")\n",
    "test_data_file = \"Data/KDD/corrected.gz\"\n",
    "test_raw_data = sc.textFile(test_data_file)\n",
    "print \"Test data size is {}\".format(test_raw_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement \n",
    "<p>The task for the classifier learning was to learn a predictive model (i.e. a classifier) capable of distinguishing between legitimate and illegitimate connections in a computer network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from numpy import array\n",
    "\n",
    "csv_data = raw_data.map(lambda x: x.split(\",\"))\n",
    "test_csv_data = test_raw_data.map(lambda x: x.split(\",\"))\n",
    "\n",
    "protocols = csv_data.map(lambda x: x[1]).distinct().collect()\n",
    "services = csv_data.map(lambda x: x[2]).distinct().collect()\n",
    "flags = csv_data.map(lambda x: x[3]).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python lists to create_labeled_point function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def create_labeled_point(line_split):\n",
    "    # leave_out = [41]\n",
    "    clean_line_split = line_split[0:41]\n",
    "    # convert protocol to numeric categorical variable\n",
    "    try: \n",
    "        clean_line_split[1] = protocols.index(clean_line_split[1])\n",
    "    except:\n",
    "        clean_line_split[1] = len(protocols)\n",
    "    # convert service to numeric categorical variable\n",
    "    try:\n",
    "        clean_line_split[2] = services.index(clean_line_split[2])\n",
    "    except:\n",
    "        clean_line_split[2] = len(services)\n",
    "    # convert flag to numeric categorical variable\n",
    "    try:\n",
    "        clean_line_split[3] = flags.index(clean_line_split[3])\n",
    "    except:\n",
    "        clean_line_split[3] = len(flags)\n",
    "    # convert label to binary label\n",
    "    attack = 1.0\n",
    "    if line_split[41]=='normal.':\n",
    "        attack = 0.0     \n",
    "    return LabeledPoint(attack, array([float(x) for x in clean_line_split]))\n",
    "\n",
    "training_data = csv_data.map(create_labeled_point)\n",
    "test_data = test_csv_data.map(create_labeled_point)\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training a classifier</h2>\n",
    "<p>We are now ready to train our classification tree.\n",
    "We will keep the maxDepth value small. \n",
    "This will lead to smaller accuracy, but we will obtain less splits so later on we can better interpret the tree.\n",
    "In a production system you can try to increase this value in order to find a better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier trained in 222.093 seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from time import time\n",
    "# Build the model\n",
    "t0 = time()\n",
    "tree_model = DecisionTree.trainClassifier(training_data, numClasses=2, \n",
    "                                          categoricalFeaturesInfo={1: len(protocols), 2: len(services), 3: len(flags)},\n",
    "                                          impurity='gini', maxDepth=4, maxBins=100)\n",
    "tt = time() - t0\n",
    "print \"Classifier trained in {} seconds\".format(round(tt,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to measure the classification error on our test data, we use map on the test_data RDD and the model to predict each test point class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made in 16.353 seconds. Test accuracy is 0.9181\n"
     ]
    }
   ],
   "source": [
    "predictions = tree_model.predict(test_data.map(lambda p: p.features))\n",
    "labels_and_preds = test_data.map(lambda p: p.label).zip(predictions)\n",
    "t0 = time()\n",
    "test_accuracy = labels_and_preds.filter(lambda (v, p): v == p).count() / float(test_data.count())\n",
    "tt = time() - t0\n",
    "print \"Prediction made in {} seconds. Test accuracy is {}\".format(round(tt,3), round(test_accuracy,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Interpreting the model</h2>\n",
    "Understanding our tree splits is a great exercise in order to explain our classification labels in terms of predictors and the values they take. Using the toDebugString method in our three model we can obtain a lot of information regarding splits, nodes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned classification tree model:\n",
      "DecisionTreeModel classifier of depth 4 with 29 nodes\n",
      "  If (feature 22 <= 68.0)\n",
      "   If (feature 25 <= 0.5)\n",
      "    If (feature 36 <= 0.4)\n",
      "     If (feature 34 <= 0.92)\n",
      "      Predict: 0.0\n",
      "     Else (feature 34 > 0.92)\n",
      "      Predict: 1.0\n",
      "    Else (feature 36 > 0.4)\n",
      "     If (feature 2 in {0.0,3.0,15.0,26.0,36.0,67.0,27.0,18.0,4.0,7.0,20.0,24.0,43.0,44.0,46.0,47.0,55.0,57.0,58.0,60.0,42.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 2 not in {0.0,3.0,15.0,26.0,36.0,67.0,27.0,18.0,4.0,7.0,20.0,24.0,43.0,44.0,46.0,47.0,55.0,57.0,58.0,60.0,42.0})\n",
      "      Predict: 1.0\n",
      "   Else (feature 25 > 0.5)\n",
      "    If (feature 3 in {7.0,4.0,9.0,2.0,3.0,10.0})\n",
      "     If (feature 2 in {3.0,5.0,7.0,8.0,15.0,18.0,50.0,51.0,67.0,12.0,27.0,42.0,58.0,68.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 2 not in {3.0,5.0,7.0,8.0,15.0,18.0,50.0,51.0,67.0,12.0,27.0,42.0,58.0,68.0})\n",
      "      Predict: 1.0\n",
      "    Else (feature 3 not in {7.0,4.0,9.0,2.0,3.0,10.0})\n",
      "     If (feature 38 <= 0.09)\n",
      "      Predict: 0.0\n",
      "     Else (feature 38 > 0.09)\n",
      "      Predict: 1.0\n",
      "  Else (feature 22 > 68.0)\n",
      "   If (feature 5 <= 0.0)\n",
      "    If (feature 11 <= 0.0)\n",
      "     If (feature 31 <= 254.0)\n",
      "      Predict: 1.0\n",
      "     Else (feature 31 > 254.0)\n",
      "      Predict: 1.0\n",
      "    Else (feature 11 > 0.0)\n",
      "     If (feature 2 in {12.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 2 not in {12.0})\n",
      "      Predict: 1.0\n",
      "   Else (feature 5 > 0.0)\n",
      "    If (feature 29 <= 0.08)\n",
      "     If (feature 4 <= 28.0)\n",
      "      Predict: 1.0\n",
      "     Else (feature 4 > 28.0)\n",
      "      Predict: 0.0\n",
      "    Else (feature 29 > 0.08)\n",
      "     Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Learned classification tree model:\"\n",
    "print tree_model.toDebugString()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
